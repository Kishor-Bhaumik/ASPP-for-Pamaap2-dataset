{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"aspp-pamaap2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"moxXtmRAxhyW","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1569351768929,"user_tz":-360,"elapsed":943,"user":{"displayName":"Kishor Kumar Bhaumik","photoUrl":"","userId":"10041133773810708456"}},"outputId":"4e4f0205-a500-4c8d-894f-01388446bde1"},"source":["import torch\n","\n","\n","# check if CUDA is available\n","train_on_gpu = torch.cuda.is_available()\n","\n","if not train_on_gpu:\n","    print('CUDA is not available.  Training on CPU ...')\n","else:\n","    print('CUDA is available!  Training on GPU ...')\n","    \n","if torch.cuda.device_count() > 0:\n","  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CUDA is available!  Training on GPU ...\n","Let's use 1 GPUs!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a4qa0lQDveOa","colab":{"base_uri":"https://localhost:8080/","height":126},"executionInfo":{"status":"ok","timestamp":1569240739598,"user_tz":-360,"elapsed":57981,"user":{"displayName":"Kishor Kumar Bhaumik","photoUrl":"","userId":"10041133773810708456"}},"outputId":"d8c44965-84e8-46fc-a666-5c6f8d0f26a7"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PV4efX3MUArT","colab":{"base_uri":"https://localhost:8080/","height":215},"executionInfo":{"status":"ok","timestamp":1569240757586,"user_tz":-360,"elapsed":13554,"user":{"displayName":"Kishor Kumar Bhaumik","photoUrl":"","userId":"10041133773810708456"}},"outputId":"1b6a24f3-aabc-4789-db7e-e06a1d7b336a"},"source":["!pip install window_slider"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting window_slider\n","  Downloading https://files.pythonhosted.org/packages/5f/44/0a2bce60022902238aac90bd933de9b9ac2215811115afc03ed39db2b9c5/window_slider-0.8.zip\n","Building wheels for collected packages: window-slider\n","  Building wheel for window-slider (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for window-slider\u001b[0m\n","\u001b[?25h  Running setup.py clean for window-slider\n","Failed to build window-slider\n","Installing collected packages: window-slider\n","  Running setup.py install for window-slider ... \u001b[?25l\u001b[?25hdone\n","Successfully installed window-slider-0.8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WAP-9LIqv1Az","colab":{"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"status":"ok","timestamp":1569240794221,"user_tz":-360,"elapsed":11634,"user":{"displayName":"Kishor Kumar Bhaumik","photoUrl":"","userId":"10041133773810708456"}},"outputId":"aadf8820-44da-4a49-aa62-a850c354cb62"},"source":["import pandas as pd\n","import numpy as np\n","import torch\n","from window_slider import Slider\n","from torch.utils import data as D\n","\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","\n","\n","df=pd.read_csv('drive/My Drive/Sensor Data/allraw.csv',index_col=0)\n","df=df[df.columns[~df.columns.str.contains('magnetometer')]]\n","\n","rep=df['activityID'].unique()\n","val=[i for i in range(11)]\n","df['activityID'].replace(rep,val,inplace=True)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  mask |= (ar1 == a)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"1B8REyIvx2l2"},"source":["def get2d(dfr,dfx,fst,scnd,height,width,overlap_count,lst):\n","  \n","  indx=np.arange(fst,scnd+1)\n","  slider = Slider(width,overlap_count)\n","  slider.fit(indx) \n","   #i=0 \n","  while True: \n","    window_data = slider.slide()\n","    if slider.reached_end_of_list():break\n","    start=window_data[0]\n","    end  =window_data[-1]+1        \n","    label=dfr['activityID'][start]        \n","    ####\n","    #check index with corresponding label\n","#         if(i==0):print(start,label)\n","#         i+=1     \n","    ####       \n","    slic=dfx[start:end:].T\n","    as_image=np.reshape(slic.values, (-1,height,width))   \n","    lst.append([as_image,label])\n","  return lst\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EJECDIqmvsbb"},"source":["def getasimage(dfr,width,overlap):\n","  \n","\n","  sub=dfr['subject'].unique()\n","  act=dfr['activityID'].unique()\n","  overlap_count = int(width*overlap)\n","  dfx=dfr.drop(columns=['timestamp-s','activityID','subject'])    \n","  Index=dfr.ne(dfr.shift()).filter(like='activityID').apply(lambda x: x.index[x].tolist())[0] \n","  length=len(Index)-1\n","  lastval=len(dfx)-1\n","  high=dfx.shape[1] #18\n","  data=[]\n","  for i in range(length):\n","    first=Index[i]\n","    second=Index[i+1]\n","    data=get2d(dfr,dfx,first,second,high,width,overlap_count,data)\n","\n","  data=get2d(dfr,dfx,second,lastval,high,width,overlap_count,data)\n","  return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q7M-T6UDsOlH"},"source":["import os\n","import random\n","\n","def seed_torch(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    \n","seed_torch(1029)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dQmCl_4Bx4kS"},"source":["import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","# from modeling.sync_batchnorm.batchnorm import SynchronizedBatchNorm2d\n","\n","class _ASPPModule(nn.Module):\n","    def __init__(self, inplanes, planes, kernel_size, padding, dilation, BatchNorm):\n","        super(_ASPPModule, self).__init__()\n","        self.atrous_conv = nn.Conv2d(inplanes, planes, kernel_size=kernel_size,\n","                                            stride=1, padding=padding, dilation=dilation, bias=False)\n","        self.bn = BatchNorm(planes)\n","        self.relu = nn.ReLU()\n","\n","        self._init_weight()\n","\n","    def forward(self, x):\n","        x = self.atrous_conv(x)\n","        x = self.bn(x)\n","\n","        return self.relu(x)\n","\n","    def _init_weight(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                torch.nn.init.kaiming_normal_(m.weight)\n","#             elif isinstance(m, SynchronizedBatchNorm2d):\n","#                 m.weight.data.fill_(1)\n","#                 m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","class ASPP(nn.Module):\n","    def __init__(self, inputs,ouputs, output_stride, BatchNorm):\n","        super(ASPP, self).__init__()\n","\n","        inplanes = inputs\n","        if output_stride == 16:\n","            dilations = [1, 6, 12, 18]\n","        elif output_stride == 8:\n","            dilations = [1, 12, 24, 36]\n","        else:\n","            raise NotImplementedError\n","\n","        self.aspp1 = _ASPPModule(inplanes, ouputs, 1, padding=0, dilation=dilations[0], BatchNorm=BatchNorm)\n","        self.aspp2 = _ASPPModule(inplanes, ouputs, 3, padding=dilations[1], dilation=dilations[1], BatchNorm=BatchNorm)\n","        self.aspp3 = _ASPPModule(inplanes, ouputs, 3, padding=dilations[2], dilation=dilations[2], BatchNorm=BatchNorm)\n","        self.aspp4 = _ASPPModule(inplanes, ouputs, 3, padding=dilations[3], dilation=dilations[3], BatchNorm=BatchNorm)\n","\n","        self.global_avg_pool = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n","                                             nn.Conv2d(inplanes, ouputs, 1, stride=1, bias=False),\n","                                             BatchNorm(ouputs),\n","                                             nn.ReLU())\n","        self.conv1 = nn.Conv2d(160, ouputs, 1, bias=False)\n","        self.bn1 = BatchNorm(ouputs)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(0.5)\n","        self._init_weight()\n","\n","    def forward(self, x):\n","        x1 = self.aspp1(x)\n","        x2 = self.aspp2(x)\n","        x3 = self.aspp3(x)\n","        x4 = self.aspp4(x)\n","        x5 = self.global_avg_pool(x)\n","        x5 = F.interpolate(x5, size=x4.size()[2:], mode='bilinear', align_corners=True)\n","        x = torch.cat((x1, x2, x3, x4, x5), dim=1)\n","\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","\n","        return self.dropout(x)\n","\n","    def _init_weight(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","                torch.nn.init.kaiming_normal_(m.weight)\n","#             elif isinstance(m, SynchronizedBatchNorm2d):\n","#                 m.weight.data.fill_(1)\n","#                 m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","\n","def build_aspp(inputs,outputs, output_stride, BatchNorm):\n","    return ASPP(inputs,outputs, output_stride, BatchNorm)\n","\n","# inn = torch.randn(2,20,32,32)\n","# mode=build_aspp(20,32,8,nn.BatchNorm2d)\n","# out=mode(inn)\n","# out.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d3a4_CD3zYOL"},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(1, 20, 3, padding=1)\n","        \n","        self.aspp = build_aspp(20, 32,output_stride=8, BatchNorm=nn.BatchNorm2d) \n","\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n","\n","        self.pool = nn.MaxPool2d(2, 2)\n","        # linear layer ([20, 64, 4, 12]-> 500)\n","        self.fc1 = nn.Linear(3072, 500)\n","        # linear layer (500 -> 10)\n","        self.fc2 = nn.Linear(500, 11)\n","        # dropout layer (p=0.25)\n","        self.dropoutcn = nn.Dropout(0.25)\n","        self._init_weight()\n","        \n","\n","    def _init_weight(self):\n","        for m in self.modules():\n","          if type(m) == nn.Linear:\n","              nn.init.xavier_uniform(m.weight)\n","              m.bias.data.fill_(0.01)\n","        \n","\n","\n","    def forward(self, x):\n","        \n","        # add sequence of convolutional and max pooling layers\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x=self.aspp(x)\n","        \n","        x = self.pool(F.relu(self.conv2(x)))\n","        \n","        # add dropout layer\n","        x = self.dropoutcn(x)\n","        \n","        x = x.view(-1,3072) \n","        # add 1st hidden layer, with relu activation function\n","        x = F.relu(self.fc1(x))\n","        # add dropout layer\n","        x = self.dropoutcn(x)\n","        # add 2nd hidden layer, with relu activation function\n","        x = F.relu(self.fc2(x))\n","        \n","#        # this is for upsampling\n","#         x=F.interpolate(x, size=[30,30], mode='bilinear',align_corners=True)\n","        \n","        return F.log_softmax(x, dim=1)\n","\n","# create a complete CNN\n","\n","device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model = Net()\n","# model=model.to(device)\n","# print(model.fc1.weight.type())\n","\n","\n","# inn = torch.randn(20,1,18,50)\n","# inn=inn.to(device)\n","# out=model(inn)\n","# out\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nH61dcsy_jsb"},"source":["# model_save_name = 'classifier.pt'\n","# path = F\"drive/My Drive/Sensor Data/{model_save_name}\" \n","# # torch.save(model.state_dict(), path)\n","# torch.save({'state_dict': model.state_dict()}, path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w9yq0UjELkG_"},"source":["def trainmodel(train_loader,n_epochs):\n","  \n","#   path = \"drive/My Drive/Sensor Data/classifier.pt\" \n","#   the_model=torch.load(path)['state_dict']\n","#   model=the_model\n","\n","\n","  model = Net()\n","#   state_dict = torch.load(path)['state_dict']\n","#   model.load_state_dict(state_dict)\n","  model=model.to(device)\n","  optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n","  model.train()\n","\n","  for epoch in range(n_epochs):\n","    train_loss = 0.0\n","    for data, target in train_loader:\n","\n","      data=data.float()\n","      target=target.long()\n","      data,target= data.to(device),target.to(device)\n","      optimizer.zero_grad()\n","      output = model(data)\n","#       loss = criterion(output, target)\n","      loss=F.nll_loss(output, target)\n","      loss.backward()\n","      optimizer.step()\n","      \n","      train_loss+=loss.item()*data.size(0)\n","      \n","    train_loss = train_loss/len(train_loader.sampler)\n","\n","    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1,train_loss))\n","    \n","  path = \"drive/My Drive/Sensor Data/checkpoint.pth\" \n","  checkpoint = {'model': Net(), 'state_dict': model.state_dict(),'optimizer' : optimizer.state_dict()}\n","  torch.save(checkpoint, path)\n","\n","  \n","\n","\n","def load_checkpoint(filepath):\n","    checkpoint = torch.load(filepath)\n","    model = checkpoint['model']\n","    model.load_state_dict(checkpoint['state_dict'])\n","    for parameter in model.parameters():\n","        parameter.requires_grad = False\n","    \n","    model.eval()\n","    \n","    return model\n"," \n","  \n","def testmodel(test_loader):\n","\n","  correct = 0\n","  total = 0\n","  path =  \"drive/My Drive/Sensor Data/checkpoint.pth\" \n","  model = load_checkpoint(path)  \n","  \n","  with torch.no_grad():\n","      for data,target in test_loader:\n","        \n","          data=data.float()\n","          target=target.long()\n","          data,target= data.to(device),target.to(device)\n","          outputs = modell(data)\n","          _, predicted = torch.max(outputs.data, 1)\n","          total += target.size(0)\n","          correct += (predicted == target).sum().item()\n","  print(\"total {} correct {}\".format(total,correct))\n","  print('Accuracy of the network on test data: %d %%' % (100 * correct / total))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"th2ouUUPx-wR","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"error","timestamp":1569253226747,"user_tz":-360,"elapsed":1597,"user":{"displayName":"Kishor Kumar Bhaumik","photoUrl":"","userId":"10041133773810708456"}},"outputId":"39dd59ef-f2f5-44d4-9d63-48ea0092ccf2"},"source":["modell = TheModelClass(*args, **kwargs)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-4316cbd0a485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTheModelClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'TheModelClass' is not defined"]}]},{"cell_type":"code","metadata":{"id":"KM5ovNsGOVdv","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1569250215104,"user_tz":-360,"elapsed":8565927,"user":{"displayName":"Kishor Kumar Bhaumik","photoUrl":"","userId":"10041133773810708456"}},"outputId":"00ac9835-2aa7-4b83-a25a-5fd4fa1029fa"},"source":["from statistics import mean \n","classes=['1ly1','2sit2','3stand3','4iron17','5vacClean16','6asStair12','7desStair13','8walk4','9run7','10cycl6',    \n","       '11nordwalk5']\n","# seed_torch(1029)\n","\n","# seed = 0\n","# torch.manual_seed(seed)\n","# if torch.cuda.is_available():\n","#     torch.cuda.manual_seed_all(seed)\n","\n","criterion=nn.CrossEntropyLoss()\n","\n","  \n","# number of subprocesses to use for data loading\n","num_workers = 0\n","batch_size = 20\n","epoch=5\n","overlp=.9\n","wdth=50\n","a=df['subject'].unique()\n","l=len(a)\n","acc=[]\n","\n","def resind(df):\n","  df.reset_index(drop=True,inplace=True)\n","  return df\n","\n","for i in range(l):\n","  \n","  trains=df[(df.subject != a[i])]\n","  tests=df.loc[df['subject'].isin([a[i]])]\n","  \n","  trains=resind(trains)\n","  tests=resind(tests)\n","\n","  train_data=getasimage(trains,wdth,overlp)\n","\n","  test_data=getasimage(tests,wdth,overlp)\n","\n","  train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,num_workers=num_workers)\n","  test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,num_workers=num_workers)\n","\n","  m=trainmodel(train_loader,epoch)\n","  testmodel(test_loader,m)\n","  \n","#   print(\"subject no. {} has accuracy {}\".format(a[i],accuracy))\n","#   acc.append(accuracy)\n","  print('\\n')  \n","  \n","# print('\\n')  \n","# print(\"***********\")\n","# print('\\n')\n","# print('Average accuracy: ',mean(acc))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1 \tTraining Loss: 0.085830\n","Epoch: 2 \tTraining Loss: 0.046212\n","Epoch: 3 \tTraining Loss: 0.044621\n","Epoch: 4 \tTraining Loss: 0.040010\n","Epoch: 5 \tTraining Loss: 0.036947\n","total 35801 correct 10439\n","Accuracy of the network on test data: 29 %\n","\n","\n","Epoch: 1 \tTraining Loss: 0.137411\n","Epoch: 2 \tTraining Loss: 0.107432\n","Epoch: 3 \tTraining Loss: 0.120296\n","Epoch: 4 \tTraining Loss: 0.114072\n","Epoch: 5 \tTraining Loss: 0.111004\n","total 38979 correct 11116\n","Accuracy of the network on test data: 28 %\n","\n","\n","Epoch: 1 \tTraining Loss: 0.159676\n","Epoch: 2 \tTraining Loss: 0.137562\n","Epoch: 3 \tTraining Loss: 0.123161\n","Epoch: 4 \tTraining Loss: 0.122594\n","Epoch: 5 \tTraining Loss: 0.113291\n","total 39608 correct 4826\n","Accuracy of the network on test data: 12 %\n","\n","\n","Epoch: 1 \tTraining Loss: 0.103770\n","Epoch: 2 \tTraining Loss: 0.073533\n","Epoch: 3 \tTraining Loss: 0.062485\n","Epoch: 4 \tTraining Loss: 0.046425\n","Epoch: 5 \tTraining Loss: 0.037630\n","total 43017 correct 5701\n","Accuracy of the network on test data: 13 %\n","\n","\n","Epoch: 1 \tTraining Loss: 0.091547\n","Epoch: 2 \tTraining Loss: 0.055563\n","Epoch: 3 \tTraining Loss: 0.048764\n","Epoch: 4 \tTraining Loss: 0.050456\n","Epoch: 5 \tTraining Loss: 0.050796\n","total 42392 correct 531\n","Accuracy of the network on test data: 1 %\n","\n","\n","Epoch: 1 \tTraining Loss: 0.077431\n","Epoch: 2 \tTraining Loss: 0.050618\n","Epoch: 3 \tTraining Loss: 0.042888\n","Epoch: 4 \tTraining Loss: 0.036792\n","Epoch: 5 \tTraining Loss: 0.032001\n","total 45403 correct 4509\n","Accuracy of the network on test data: 9 %\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ugx9ibl8mcOy","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1569252299989,"user_tz":-360,"elapsed":1414201,"user":{"displayName":"Kishor Kumar Bhaumik","photoUrl":"","userId":"10041133773810708456"}},"outputId":"ffb844d2-8efe-4a6f-918a-1f867289939f"},"source":["import time\n","import datetime\n","\n","start_time = time.time()\n","\n","criterion=nn.CrossEntropyLoss()\n","\n","\n","# prep model for training\n","\n","\n","\n","trains=df[(df.subject != 107)]\n","tests=df.loc[df['subject'].isin([107])]\n","\n","trains=resind(trains)\n","tests=resind(tests)\n","\n","train_data=getasimage(trains,wdth,overlp)\n","\n","test_data=getasimage(tests,wdth,overlp)\n","\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,num_workers=num_workers)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,num_workers=num_workers)\n","\n","n_epochs = 10\n","model=Net()\n","model=model.to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n","model.train() \n","\n","for epoch in range(n_epochs):\n","  train_loss = 0.0\n","  for data, target in train_loader:\n","\n","    data=data.float()\n","    target=target.long()\n","    data,target= data.to(device),target.to(device)\n","    optimizer.zero_grad()\n","    output = model(data)\n","#       loss = criterion(output, target)\n","    loss=F.nll_loss(output, target)\n","    loss.backward()\n","    optimizer.step()\n","\n","    train_loss+=loss.item()*data.size(0)\n","\n","  train_loss = train_loss/len(train_loader.sampler)\n","\n","  print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1,train_loss))\n","\n","print(\" \")\n","b=(time.time() - start_time)\n","print(\"Running time= \" , str(datetime.timedelta(seconds=b)))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (conv1): Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (aspp): ASPP(\n","    (aspp1): _ASPPModule(\n","      (atrous_conv): Conv2d(20, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU()\n","    )\n","    (aspp2): _ASPPModule(\n","      (atrous_conv): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n","      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU()\n","    )\n","    (aspp3): _ASPPModule(\n","      (atrous_conv): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n","      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU()\n","    )\n","    (aspp4): _ASPPModule(\n","      (atrous_conv): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n","      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU()\n","    )\n","    (global_avg_pool): Sequential(\n","      (0): AdaptiveAvgPool2d(output_size=(1, 1))\n","      (1): Conv2d(20, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (3): ReLU()\n","    )\n","    (conv1): Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU()\n","    (dropout): Dropout(p=0.5)\n","  )\n","  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (fc1): Linear(in_features=3072, out_features=500, bias=True)\n","  (fc2): Linear(in_features=500, out_features=11, bias=True)\n","  (dropoutcn): Dropout(p=0.25)\n",")"]},"metadata":{"tags":[]},"execution_count":22},{"output_type":"stream","text":["Epoch: 1 \tTraining Loss: 0.103184\n","Epoch: 2 \tTraining Loss: 0.072800\n","Epoch: 3 \tTraining Loss: 0.056965\n","Epoch: 4 \tTraining Loss: 0.049419\n","Epoch: 5 \tTraining Loss: 0.045113\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-b37616186e12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m#       loss = criterion(output, target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"uBZWxO4soQwQ","colab":{"base_uri":"https://localhost:8080/","height":746},"executionInfo":{"status":"ok","timestamp":1569252340537,"user_tz":-360,"elapsed":13178,"user":{"displayName":"Kishor Kumar Bhaumik","photoUrl":"","userId":"10041133773810708456"}},"outputId":"ca7fcc0a-69f3-4ef6-cd0d-1fffab5ed34a"},"source":["correct = 0\n","total = 0\n","modell=model\n","modell.eval()\n","with torch.no_grad():\n","    for data,target in test_loader:\n","\n","        data=data.float()\n","        target=target.long()\n","        data,target= data.to(device),target.to(device)\n","        outputs = modell(data)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += target.size(0)\n","        correct += (predicted == target).sum().item()\n","print(\"total {} correct {}\".format(total,correct))\n","print('Accuracy of the network on test data: %d %%' % (\n","    100 * correct / total))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (conv1): Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (aspp): ASPP(\n","    (aspp1): _ASPPModule(\n","      (atrous_conv): Conv2d(20, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU()\n","    )\n","    (aspp2): _ASPPModule(\n","      (atrous_conv): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n","      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU()\n","    )\n","    (aspp3): _ASPPModule(\n","      (atrous_conv): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n","      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU()\n","    )\n","    (aspp4): _ASPPModule(\n","      (atrous_conv): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n","      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU()\n","    )\n","    (global_avg_pool): Sequential(\n","      (0): AdaptiveAvgPool2d(output_size=(1, 1))\n","      (1): Conv2d(20, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (3): ReLU()\n","    )\n","    (conv1): Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU()\n","    (dropout): Dropout(p=0.5)\n","  )\n","  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (fc1): Linear(in_features=3072, out_features=500, bias=True)\n","  (fc2): Linear(in_features=500, out_features=11, bias=True)\n","  (dropoutcn): Dropout(p=0.25)\n",")"]},"metadata":{"tags":[]},"execution_count":25},{"output_type":"stream","text":["total 42392 correct 13540\n","Accuracy of the network on test data: 31 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jHHCMh_shRek","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1569250268467,"user_tz":-360,"elapsed":1496,"user":{"displayName":"Kishor Kumar Bhaumik","photoUrl":"","userId":"10041133773810708456"}},"outputId":"4f9b4a27-c039-4306-80d0-0278adce86fa"},"source":["df['subject'].unique()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([101, 102, 105, 106, 107, 108])"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"kuvH03yeXHkl","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1569035431624,"user_tz":-360,"elapsed":1011,"user":{"displayName":"Kishor Kumar Bhaumik","photoUrl":"","userId":"10041133773810708456"}},"outputId":"3926539c-5d08-4dbf-f1de-f195cac1efc5"},"source":["for data, target in test_loader:\n","  print(target)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n","        10, 10])\n","tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,  3,  3,  3,  3,  3,  3,\n","         3,  3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3])\n"],"name":"stdout"}]}]}